"""
Streamlit æ¼”ç¤ºåº”ç”¨ï¼šHybrid Advisor Offline
--------------------------------------------

åŠŸèƒ½æ¦‚è§ˆ
1. è½½å…¥æœ€æ–°çš„ CQL æ¨¡å‹ä¸å¸‚åœºå¿«ç…§ï¼ˆç¼“å­˜ï¼‰ã€‚
2. åœ¨å·¦ä¾§é¢æ¿è¾“å…¥å®¢æˆ·ç”»åƒã€è´¦æˆ·è§„æ¨¡ä¸é£é™©æ£€æŸ¥è®¾å®šã€‚
3. å³ä¾§å®æ—¶å±•ç¤ºåˆè§„å¯ç”¨åŠ¨ä½œçš„ Q å€¼ã€æ¨èæ’åºä¸åˆè§„è§£é‡Šã€‚
4. è¾“å‡ºå¯å¤åˆ¶çš„å®¡è®¡æ‘˜è¦ï¼Œä¾¿äºå®¡è®¡è¿½æº¯ã€‚

è¿è¡Œæ–¹å¼
    python -m streamlit run hybrid_advisor_offline/ux/demo_streamlit.py
"""

from __future__ import annotations

import hashlib
import json
from dataclasses import asdict
import os
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd
import streamlit as st

from hybrid_advisor_offline.llm.text_translator import refine_text, translator_enabled
from hybrid_advisor_offline.engine.act_safety.act_discrete_2_cards import (
    ALL_CARDS,
    get_card_by_id,
)
from hybrid_advisor_offline.engine.act_safety.act_filter import allowed_cards_for_user
from hybrid_advisor_offline.engine.envs.market_envs import MarketEnv
from hybrid_advisor_offline.engine.personal.personal_prior import (
    build_personal_prior,
    infer_prefs_from_profile,
)
from hybrid_advisor_offline.engine.policy.explain import build_explain_pack
from hybrid_advisor_offline.engine.state.state_builder import (
    MarketSnapshot,
    UserProfile,
    build_state_vec,
)
from hybrid_advisor_offline.offline.analysis.segment_metrics import plot_segment_bars
from hybrid_advisor_offline.offline.trainrl import train_cql
from hybrid_advisor_offline.offline.trainrl.train_cql import (
    load_cql_policy_from_paths,
)

PAGE_ICON = "ğŸ§­"
TOP_K = 3
REPORTS_DIR = Path("./reports")
DEMO_MODE = os.getenv("DEMO_MODE", "0") == "1"
DEMO_DATASET_PATH = os.getenv("DEMO_DATASET_PATH", "./data/offline_dataset_demo.h5")
DEMO_MODEL_PATH = os.getenv("DEMO_MODEL_PATH", "./models/cql_demo.pt")
FULL_DATASET_PATH = os.getenv(
    "STREAMLIT_DATASET_PATH",
    getattr(train_cql, "DATASET_PATH", "./data/offline_dataset.h5"),
)
FULL_MODEL_PATH = os.getenv(
    "STREAMLIT_MODEL_PATH",
    getattr(train_cql, "MODEL_SAVE_PATH", "./models/cql_discrete_model.pt"),
)


def _predict_q_values(policy, state_vec: np.ndarray) -> np.ndarray:
    action_count = len(ALL_CARDS)
    state_batch = np.repeat(state_vec[None, :], action_count, axis=0)
    action_batch = np.arange(action_count, dtype=np.int64)
    return policy.predict_value(state_batch, action_batch)


@st.cache_resource(show_spinner=False)
def load_resources(
    demo_mode: bool,
    dataset_path: str,
    model_path: str,
):
    """åŠ è½½ CQL ç­–ç•¥ä¸æœ€æ–°å¸‚åœºå¿«ç…§ï¼›å¤±è´¥æ—¶è¿”å› (None, None)ã€‚"""
    try:
        policy = load_cql_policy_from_paths(
            dataset_path,
            model_path,
            require_gpu=False,
        )
        env = MarketEnv()
        latest_snapshot: MarketSnapshot = env.mkt_sshots[-1]
        return policy, latest_snapshot
    except Exception as exc:  # pragma: no cover - UI å…œåº•
        st.error(f"æ¨¡å‹æˆ–æ•°æ®åŠ è½½å¤±è´¥ï¼š{exc}")
        return None, None


def _collect_user_inputs() -> Dict:
    st.sidebar.subheader("å®¢æˆ·ç”»åƒä¸åå¥½")

    age = st.sidebar.slider("å¹´é¾„", min_value=20, max_value=80, value=42)
    balance = int(st.sidebar.number_input("å¯æŠ•èµ„èµ„äº§ (Â¥)", min_value=10000, max_value=5_000_000, value=500_000, step=50_000))
    job = st.sidebar.selectbox(
        "èŒä¸š",
        ["management", "technician", "admin.", "services", "retired", "student", "blue-collar"],
        index=0,
    )
    marital = st.sidebar.selectbox("å©šå§»çŠ¶å†µ", ["single", "married", "divorced"], index=1)
    education = st.sidebar.selectbox("æ•™è‚²æ°´å¹³", ["primary", "secondary", "tertiary", "unknown"], index=2)
    housing = st.sidebar.radio("ä½æˆ¿è´·æ¬¾", ["yes", "no"], index=1, horizontal=True)
    loan = st.sidebar.radio("æ¶ˆè´¹è´·æ¬¾", ["yes", "no"], index=1, horizontal=True)
    default = st.sidebar.radio("å†å²è¿çº¦", ["no", "yes"], index=0, horizontal=True)

    alloc_templates = {
        "ç¨³å¥å‹ (40/40/20)": (0.4, 0.4, 0.2),
        "ä¿å®ˆå‹ (20/30/50)": (0.2, 0.3, 0.5),
        "è¿›å–å‹ (60/30/10)": (0.6, 0.3, 0.1),
    }
    alloc_label = st.sidebar.selectbox("å½“å‰ç»„åˆ", list(alloc_templates.keys()), index=0)
    current_alloc = np.array(alloc_templates[alloc_label], dtype=np.float32)

    profile = UserProfile(
        age=age,
        job=job,
        marital=marital,
        education=education,
        default=default,
        balance=balance,
        housing=housing,
        loan=loan,
    )

    return {
        "profile": profile,
        "current_alloc": current_alloc,
    }


def _format_percentage_vector(vec: List[float]) -> str:
    parts = [f"{int(x * 100):02d}%" for x in vec]
    return f"è‚¡ç¥¨ {parts[0]} / å€ºåˆ¸ {parts[1]} / ç°é‡‘ {parts[2]}"


def _list_report_files(pattern: str) -> List[Path]:
    if not REPORTS_DIR.exists():
        return []
    return sorted(REPORTS_DIR.glob(pattern))


def _render_segment_dashboard():
    csv_files = _list_report_files("segment_metrics_*.csv")
    if not csv_files:
        st.info("å½“å‰ reports/ ä¸‹æ²¡æœ‰ segment_metrics_*.csvï¼Œè¯·å…ˆè¿è¡Œåˆ†æè„šæœ¬ã€‚")
        return
    options = {f.name: f for f in csv_files}
    selected = st.selectbox("é€‰æ‹©æŒ‡æ ‡æ–‡ä»¶", list(options.keys()), key="segment_csv")
    df = pd.read_csv(options[selected])
    st.dataframe(df, use_container_width=True)
    fig = plot_segment_bars(df, output_path=None)
    st.pyplot(fig, use_container_width=True)
    fig.clf()


def _render_policy_diff_dashboard():
    json_files = _list_report_files("policy_diff_cases_*.json")
    if not json_files:
        st.info("å½“å‰ reports/ ä¸‹æ²¡æœ‰ policy_diff_cases_*.jsonã€‚")
        return
    options = {f.name: f for f in json_files}
    selected = st.selectbox("é€‰æ‹©ç­–ç•¥å·®å¼‚æ–‡ä»¶", list(options.keys()), key="policy_diff_file")
    with options[selected].open("r", encoding="utf-8") as fp:
        cases = json.load(fp)
    if not cases:
        st.warning("æ–‡ä»¶ä¸ºç©ºã€‚")
        return
    segments = sorted({case.get("user_segment", "unknown") for case in cases})
    seg_choice = st.selectbox("ç­›é€‰åˆ†ç»„", segments, key="policy_diff_segment")
    filtered = [case for case in cases if case.get("user_segment") == seg_choice]
    if not filtered:
        st.info("è¯¥åˆ†ç»„ä¸‹æš‚æ— æ ·æœ¬ã€‚")
        return
    limit = st.slider(
        "å±•ç¤ºæ ·æœ¬æ•°é‡",
        min_value=1,
        max_value=min(len(filtered), 20),
        value=min(5, len(filtered)),
        key="policy_diff_limit",
    )
    rows = []
    for case in filtered[:limit]:
        row = {
            "segment": case.get("user_segment"),
            "state_step": case.get("state_step"),
            "rule_card": case.get("rule", {}).get("card_id"),
            "rule_equity": case.get("rule", {}).get("equity_weight"),
            "bc_card": case.get("bc", {}).get("card_id"),
            "bcq_card": case.get("bcq", {}).get("card_id"),
        }
        rows.append(row)
    st.table(pd.DataFrame(rows))


def render_recommendations(policy, snapshot, profile: UserProfile, current_alloc: np.ndarray):
    state_vec = build_state_vec(snapshot, profile, current_alloc)
    q_values = _predict_q_values(policy, state_vec)

    allowed_cards = allowed_cards_for_user(profile.risk_bucket)
    allowed_ids = [card.act_id for card in allowed_cards]

    priors = build_personal_prior(
        allowed_ids,
        prefs=infer_prefs_from_profile(profile),
        risk_bucket=profile.risk_bucket,
    )

    mask = np.full_like(q_values, -np.inf, dtype=np.float32)
    for act_id in allowed_ids:
        if 0 <= act_id < len(mask):
            mask[act_id] = 0.0
    masked_q = q_values + mask
    if priors:
        prior_vec = np.zeros_like(q_values)
        for act_id, bump in priors.items():
            if 0 <= act_id < len(prior_vec):
                prior_vec[act_id] = bump
        masked_q = masked_q + prior_vec

    ranked_ids = sorted(allowed_ids, key=lambda aid: masked_q[aid], reverse=True)
    if not ranked_ids:
        st.warning("å½“å‰çº¦æŸä¸‹æ²¡æœ‰å¯ç”¨çš„åŠ¨ä½œå¡ç‰‡ï¼Œè¯·è°ƒæ•´è¾“å…¥ã€‚")
        return

    if translator_enabled():
        st.info("æ–‡æ¡ˆæ¶¦è‰²ï¼šå·²å¼€å¯ï¼ˆUSE_LLM_TRANSLATOR=1ï¼‰", icon="âœ¨")
    else:
        st.info("æ–‡æ¡ˆæ¶¦è‰²ï¼šå…³é—­ï¼Œå¯è®¾ç½® USE_LLM_TRANSLATOR=1 å¯ç”¨ã€‚", icon="ğŸ’¬")

    st.markdown("### æ¨èå¡ç‰‡ TOP-3")
    for idx, act_id in enumerate(ranked_ids[:TOP_K], start=1):
        card = get_card_by_id(act_id)
        explain_pack = build_explain_pack(card, profile.risk_bucket)
        explain_text, translator_meta = refine_text(
            explain_pack["customer_friendly_text"],
            {
                "card_id": card.card_id,
                "card_risk_level": card.risk_level,
                "user_risk_bucket": profile.risk_bucket,
                "target_alloc": card.target_alloc,
            },
        )
        q_score = float(masked_q[act_id])
        hash_digest = hashlib.sha256(explain_pack["audit_text"].encode("utf-8")).hexdigest()[:12]
        with st.container(border=True):
            st.write(f"**#{idx} Â· {card.card_id}** ï½œ ç›®æ ‡é…ç½® {_format_percentage_vector(card.target_alloc)}")
            cols = st.columns([1, 1, 1])
            cols[0].metric("æ¨¡å‹ Q å€¼", f"{q_score:.3f}")
            cols[1].metric("ç­–ç•¥é£é™©", ["ä¿å®ˆ", "ç¨³å¥", "è¿›å–"][card.risk_level])
            cols[2].metric("å®¡è®¡æ‘˜è¦å“ˆå¸Œ", hash_digest)
            st.caption(explain_text)
            if translator_meta not in ("translator_disabled", "translator_no_change"):
                st.caption(f"ï¼ˆæ–‡æ¡ˆæ¶¦è‰²ï¼š{translator_meta}ï¼‰")

    st.markdown("---")
    st.markdown("#### åˆè§„å¯ç”¨åŠ¨ä½œçš„ Q å€¼åˆ†å¸ƒ")
    df = pd.DataFrame(
        {
            "card_id": [get_card_by_id(aid).card_id for aid in allowed_ids],
            "q_value": [float(masked_q[aid]) for aid in allowed_ids],
        }
    ).sort_values("q_value", ascending=False)
    st.bar_chart(df, x="card_id", y="q_value", color="#4B8BBE")

    with st.expander("åŸå§‹å®¢æˆ·ç”»åƒ / çŠ¶æ€å‘é‡ç‰¹å¾"):
        st.json({"profile": asdict(profile), "current_alloc": current_alloc.tolist()})


def render_analysis_tab():
    st.subheader("åˆ†ç¾¤æŒ‡æ ‡ï¼ˆCSVï¼‰")
    _render_segment_dashboard()
    st.markdown("---")
    st.subheader("ç­–ç•¥å·®å¼‚æ ·æœ¬")
    _render_policy_diff_dashboard()


def main():
    st.set_page_config(
        page_title="Hybrid Advisor Offline Demo",
        page_icon=PAGE_ICON,
        layout="wide",
    )
    st.title("Hybrid Advisor Offline Â· å‰ç«¯æ¼”ç¤º")
    st.caption(
        "ç¦»çº¿ CQL æ¨¡å‹ + åˆè§„å®‰å…¨å£³ã€‚è¾“å…¥å®¢æˆ·ç”»åƒåå³å¯æŸ¥çœ‹æ¨èå¡ç‰‡ã€Q å€¼ä¸å®¡è®¡æ‘˜è¦ã€‚"
    )

    active_dataset = DEMO_DATASET_PATH if DEMO_MODE else FULL_DATASET_PATH
    active_model = DEMO_MODEL_PATH if DEMO_MODE else FULL_MODEL_PATH
    policy, snapshot = load_resources(DEMO_MODE, active_dataset, active_model)
    if policy is None or snapshot is None:
        st.stop()

    inputs = _collect_user_inputs()

    tab_reco, tab_analysis = st.tabs(["å®æ—¶æ¨è", "åƒäººåƒé¢åˆ†æ"])
    with tab_reco:
        col_left, col_right = st.columns([0.35, 0.65], gap="large")
        with col_left:
            st.subheader("å®‰å…¨å£³&çŠ¶æ€æ€»è§ˆ")
            if DEMO_MODE:
                st.info(
                    "Demo æ¨¡å¼ï¼šä½¿ç”¨è½»é‡å°æ¨¡å‹ï¼Œä»…ç”¨äºå¿«é€Ÿå±•ç¤ºã€‚",
                    icon="âš¡",
                )
            st.metric("é£é™©ç­‰çº§ (0=ä¿å®ˆ,2=è¿›å–)", inputs["profile"].risk_bucket)
            st.metric(
                "å½“å‰é…ç½®",
                _format_percentage_vector(inputs["current_alloc"]),
                help="ç”¨äºæ‹¼æ¥çŠ¶æ€å‘é‡ï¼Œä¹Ÿå¯ä½œä¸ºç»„åˆè°ƒä»“å‚è€ƒã€‚",
            )
        with col_right:
            render_recommendations(
                policy,
                snapshot,
                profile=inputs["profile"],
                current_alloc=inputs["current_alloc"],
            )

    with tab_analysis:
        render_analysis_tab()

    st.sidebar.markdown("---")
    st.sidebar.markdown(
        "âœ… å½“å‰ç•Œé¢ä»…ç”¨äºæ¼”ç¤ºï¼Œä¸ä¼šè§¦å‘çœŸå®äº¤æ˜“ã€‚\n\n"
        "â˜‘ï¸ å½“ CQL æ¨¡å‹æˆ–æ•°æ®æœªå‡†å¤‡å¥½æ—¶ï¼Œåº”ç”¨ä¼šæç¤ºé”™è¯¯ã€‚"
    )


if __name__ == "__main__":
    main()
